{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de vendas de um e-commerce\n",
    "\n",
    "por [Lucas Fiorani Diniz](https://www.linkedin.com/in/lcfdiniz/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do problema\n",
    "\n",
    "O e-commerce é um modelo de negócios onde há a compra e venda de produtos totalmente através da internet. Isso inclui a seleção desses produtos, a definição de um endereço para a entrega, a escolha de uma forma de pagamento e a conclusão da compra propriamente dita [[1]](https://exame.com/invest/guia/o-que-e-e-commerce-red04/). Essa forma de transação comercial tem se tornado cada vez mais predominante na era digital, permitindo a comerciantes expandir seu alcance geográfico e reduzir os custos operacionais, ao mesmo tempo em que oferece aos consumidores um processo de compra mais conveniente, com diversas opções de produtos, fornecedores, preços e condições de pagamento.\n",
    "\n",
    "A tendência de alta há muito tempo observada para esse tipo de negócio experimentou um grande salto durante a crise sanitária da COVID-19, onde consumidores e comerciantes recorreram a essa modalidade diante das restrições de movimentação e lockdowns impostos pelos governos. Como resultado, o crescimento do comércio eletrônico no primeiro ano da pandemia chegou a 32,4% nos Estados Unidos e impressionantes 50% no Brasil [[2]](https://exame.com/negocios/a-pandemia-fez-o-e-commerce-decolar-ainda-ha-folego-para-mais/), período no qual 7,3 milhões de brasileiros realizaram uma compra online pela primeira vez.\n",
    "\n",
    "Dados mais recentes, de 2022, apontam para uma alta de 24% no número de consumidores e um faturamento recorde para o setor [[3]](https://www.infomoney.com.br/consumo/e-commerce-tem-alta-24-no-numero-de-consumidores-e-fatura-r-262-bi-em-2022-recorde-do-setor/), demonstrando que o crescimento do comércio online vai muito além de uma resposta temporária a crise, representando uma nova realidade em termos de hábitos de consumo. \n",
    "\n",
    "À medida em que cada vez mais se registram transações de compra e venda online, mais dados são gerados para uma posterior análise. Esses conjuntos de dados são valiosos, sendo fundamental para o sucesso de qualquer comerciante do mercado digital saber interpretá-los e extrair insights ou padrões de consumo. Sendo assim, o objetivo desse trabalho é, a partir de uma base de dados anonimizada de um e-commerce brasileiro real, responder algumas perguntas que nos ajudem a compreender os hábitos, preferências ou padrões dos consumidores brasileiros no comércio online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levantamento de questões\n",
    "\n",
    "A partir da base de dados utilizada, devem ser respondidas as seguintes perguntas:\n",
    "\n",
    "- Quais são os produtos mais vendidos no e-commerce?\n",
    "- Qual o preço médio das vendas?\n",
    "- Qual estado ou região do Brasil realiza mais compras online?\n",
    "- Qual a forma de pagamento de preferência?\n",
    "- Cada pedido possui em média quantos itens?\n",
    "\n",
    "Como uma análise bônus, seria interessante verificar a coocorrência de itens nas transações realizadas, a partir de regras de associação. A capacidade de identificar as associações de itens mais relevantes permitiria ao e-commerce recomendar produtos em carrinho de compras, por exemplo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset utilizado\n",
    "\n",
    "Para se obter os dados do problema, a plataforma [Kaggle](https://www.kaggle.com/datasets) foi consultada. O Kaggle é a maior comunidade online de cientistas de dados e praticantes de Machine Learning, disponibilizando recursos valiosos para seus usuários, como datasets variados.\n",
    "\n",
    "O melhor dataset encontrado para o problema foi o [*Brazilian E-Commerce Public Dataset by Olist*](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce). Esse conjunto de dados possui 100 mil pedidos realizados de 2016 a 2018 em diversos marketplaces no Brasil, com informações sobre os produtos negociados, vendedores, compradores, métodos de pagamento e reviews.\n",
    "\n",
    "Como contextualização, a Olist é uma startup brasileira responsável por conectar pequenos negócios com canais de venda (marketplaces) brasileiros, como Mercado Livre, B2W, Via Varejo e Amazon. Através da Olist, esses negociantes podem vender seus produtos e enviá-los utilizando os parceiros logísticos da plataforma. Sendo assim, é importante destacar que cada pedido pode conter múltiplos itens e cada item em um pedido pode pertencer a um vendedor diferente.\n",
    "\n",
    "O dataset é composto por 9 tabelas distintas:\n",
    "\n",
    "1. **Costumers**: contém informação dos clientes e sua localização;\n",
    "2. **Geolocation**: contém informações de códigos postais brasileiros e suas coordenadas de latitude e longitude;\n",
    "3. **Order Items**: contém dados sobre os items pertencentes a cada compra;\n",
    "4. **Payments**: contém dados sobre as opções de pagamento de cada compra;\n",
    "5. **Reviews**: contém os reviews feitos por clientes para cada compra;\n",
    "6. **Orders**: contém informações de cada pedido realizado;\n",
    "7. **Products**: contém informações sobre os produtos vendidos pela Olist;\n",
    "8. **Sellers**: contém informações sobre os vendedores que utilizam a plataforma da Olist;\n",
    "9. **Category Name Translation**: utilizada apenas para traduzir os nomes de categorias do português para o inglês.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de dados utilizado\n",
    "\n",
    "O pipeline de dados utilizado para esse projeto é apresentado na figura abaixo.\n",
    "\n",
    "<img src=\"./assets/aws_architecture.png\">\n",
    "\n",
    "A plataforma de computação **Amazon Web Services (AWS)** será utilizada para a realização desse trabalho. O **Amazon S3** será empregado para armazenamento dos dados em nuvem. Em seguida, o **AWS Glue** será utilizado como ferramenta de ETL, realizando a extração de dados (do S3), aplicando as transformações necessárias e realizando a carga de dados no Data Warehouse. O **AWS Redshift** será utilizado como serviço de Data Warehouse, permitindo o armazenamento e análise de dados em larga escala. O Redshift é compatível com a linguagem SQL, o que permitirá a realização de consultas para responder as questões levantadas previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta e armazenamento em nuvem\n",
    "\n",
    "O primeiro passo consiste em coletar os dados disponibilizados no Kaggle e armazená-los no Amazon S3. O S3 permite o armazenamento distribuído de objetos com grande escalabilidade, disponibilidade, segurança e performance. Cada objeto no S3 é armazenado em um **bucket**, que funciona como um container para os dados armazenados. Sendo assim, após realizar o download do dataset para a máquina local, foi criado um bucket no S3.\n",
    "\n",
    "### Criação de um bucket\n",
    "\n",
    "A única configuração ajustada foi o nome do bucket, declarado como `mvp-ecommerce-sales-analysis`. As imagens abaixo registram o processo de criação do bucket.\n",
    "\n",
    "<img src=\"./assets/s3_bucket_config.png\">\n",
    "\n",
    "<img src=\"./assets/s3_bucket_created.png\">\n",
    "\n",
    "\n",
    "### Criação de uma pasta\n",
    "\n",
    "Em seguida, foi criada uma pasta dentro do bucket. O nome atribuído para a pasta foi `ecommerce-sales-analysis`.\n",
    "\n",
    "<img src=\"./assets/s3_create_folder.png\">\n",
    "\n",
    "<img src=\"./assets/s3_folder_created.png\">\n",
    "\n",
    "### Upload de arquivos\n",
    "\n",
    "Os arquivos baixados do Kaggle foram carregados para a pasta dentro do bucket S3.\n",
    "\n",
    "<img src=\"./assets/s3_upload_files.png\">\n",
    "\n",
    "<img src=\"./assets/s3_uploaded_files.png\">\n",
    "\n",
    "<img src=\"./assets/s3_folder_with_files.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem de dados\n",
    "\n",
    "A especificação do esquema de um Data Warehouse utiliza do paradigma multidimensional como representação conceitual. Toda modelagem dimensional, por sua vez, possui dois elemento imprescindíveis: **Fatos** e **Dimensões**. Os fatos representam as medidas de interesse, quase sempre numéricas, enquanto as dimensões representam perspectivas do negócio, sobre as quais se deseja analisar essas medidas de interesse.\n",
    "\n",
    "Sendo assim, será utilizado um esquema multidimensional do tipo floco de neve para a modelagem de dados, onde a **tabela fato corresponde às vendas**, mais especificamente aos itens vendidos. À cada venda estão associadas três chaves estrangeiras que referenciam chaves primárias das tabelas dimensão Vendedor, Produto e Pedido. Os fatos representados pela tabela fato são a quantidade vendida do item, seu valor e o valor de frete associado. Por fim, as dimensões Cliente, Pagamento, Review e Tempo estão ligados a tabela dimensão Pedido, sendo essa uma característica de um esquema floco de neve.\n",
    "\n",
    "O esquema abaixo representa o modelo de dados utilizado:\n",
    "\n",
    "<img src=\"./assets/data_schema.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do ambiente em nuvem\n",
    "\n",
    "### Configurando o Amazon Redshift\n",
    "\n",
    "O Amazon Redshift Serverless foi escolhido como o serviço de Data Warehouse para esse trabalho, permitindo analisar dados sem a necessidade de definição e gerenciamento da infraestrutura subjacente. A AWS oferece 300 dólares em crédito para utilização desse serviço, que devem ser suficientes para executar o que foi proposto.\n",
    "\n",
    "Para provisionar o Amazon Redshift Serverless, é preciso configurar dois componentes: **Namespace** e **Workspace**. O Namespace é utilizado para a criação de bases de dados, esquemas, tabelas, entre outros. O Workgroup, por sua vez, permite configurar a capacidade computacional. A relação desses componentes é um para um, ou seja, um Namespace está associado a um e apenas um Workgroup, e vice versa.\n",
    "\n",
    "As imagens abaixo registram como o Amazon Redshift Serverless foi provisionado para essa aplicação:\n",
    "\n",
    "<img src=\"./assets/redshift_namespace.png\">\n",
    "\n",
    "Foi necessário criar uma função do IAM para associar ao Redshift. Para essa função, foi concedido acesso a qualquer bucket do S3 e atribuída a política `AmazonRedshiftAllCommandsFullAccess`.\n",
    "\n",
    "<img src=\"./assets/redshift_create_iam.png\">\n",
    "\n",
    "<img src=\"./assets/redshift_iam_created.png\">\n",
    "\n",
    "Em seguida, foram definidas as configurações do Workspace. Dado que as consultas realizadas serão relativamente simples para os padrões de aplicações de Big Data, a capacidade básica de RPU (Redshift Processing Unit) foi ajustada para 8, sendo esse o menor valor possível. Com isso podemos reduzir nossos custos computacionais e, consequentemente, os gastos com o serviço de nuvem.\n",
    "\n",
    "<img src=\"./assets/redshift_workgroup.png\">\n",
    "\n",
    "<img src=\"./assets/redshift_created.png\">\n",
    "\n",
    "### Criando as tabelas no Redshift\n",
    "\n",
    "Ao entrar no Workspace recém criado, foi necessário gerar uma permissão temporária para acessar a base de dados, nomeada como `dev`:\n",
    "\n",
    "<img src=\"./assets/redshift_temporary_connection.png\">\n",
    "\n",
    "Em seguida, foi criada uma query chamada de `create_tables`, responsável pela criação das tabelas e definição de seus esquemas. Como mostrado na figura abaixo, as tabelas foram criadas com sucesso:\n",
    "\n",
    "<img src=\"./assets/redshift_create_tables_1.png\">\n",
    "\n",
    "<img src=\"./assets/redshift_create_tables_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração, Transformação e Carga (ETL)\n",
    "\n",
    "Em seguida, o serviço AWS Glue foi utilizado para implementar as tarefas de ETL, chamadas de ETL jobs. É possível criar uma tarefa de ETL utilizando as linguagens Python, Scala ou Spark, ou ainda de forma visual através do AWS Glue Studio. Esse último método foi o escolhido para implementação dos ETL jobs nesse trabalho.\n",
    "\n",
    "Na criação do ETL job, foi escolhida a forma visual com origem (*source*) e alvo (*target*), onde a origem é um bucket do Amazon S3 e o alvo é o Amazon Redshift.\n",
    "\n",
    "<img src=\"./assets/glue_create_job.png\">\n",
    "\n",
    "Para manter a organização do trabalho, foram criados 7 ETL jobs, sendo um para cada tabela do conjunto de dados. As transformações aplicadas a cada conjunto de dados serão exibidas individualmente. Em relação à definição de fontes de dados, o processo foi similar, como mostrado abaixo:\n",
    "\n",
    "<img src=\"./assets/job_data_source.png\">\n",
    "\n",
    "Em cada ETL job, foi selecionada a tabela correspondente no bucket S3 e definidos o formato como CSV e a vírgula como delimitador. Em todos os casos, o esquema dos dados foi autodetectado.\n",
    "\n",
    "Em relação à definição do alvo, foi necessária a criação de uma conexão com o Redshift, como apresentado na próxima subseção.\n",
    "\n",
    "<img src=\"./assets/job_target_before.png\">\n",
    "\n",
    "\n",
    "### Criando a conexão com o Redshift\n",
    "\n",
    "Para a conexão com o Redshift, foi definido seu nome (`mvp-redshift`) e o tipo de conexão (Amazon Redshift). Em seguida, foi escolhida a instância da base de dados, selecionando o Workgroup do Redshift criado anteriormente e a base de dados `dev`.\n",
    "\n",
    "<img src=\"./assets/glue_create_connection.png\">\n",
    "\n",
    "<img src=\"./assets/glue_connection_created.png\">\n",
    "\n",
    "Para testarmos a nova conexão, será necessária a criação de uma nova função do IAM e de um endpoint, conforme detalhado nas próximas subseções.\n",
    "\n",
    "### Criando uma função do IAM\n",
    "\n",
    "O tipo de entidade confiável foi definido como \"Serviço da AWS\", enquanto para o caso de uso foi escolhido o Glue, conforme apresentado na figura abaixo.\n",
    "\n",
    "<img src=\"./assets/iam_create_role.png\">\n",
    "\n",
    "Por simplicidade, foi atribuída a política `AdministratorAccess` a essa função.\n",
    "\n",
    "<img src=\"./assets/iam_role_permissions.png\">\n",
    "\n",
    "Por fim, a função do IAM foi nomeada como `Mvp-Glue`.\n",
    "\n",
    "<img src=\"./assets/iam_role_details.png\">\n",
    "\n",
    "### Criando um endpoint\n",
    "\n",
    "É necessário criar um endpoint para que os recursos dentro da Virtual Private Cloud (VPC), como o AWS Glue e Amazon Redshift, possam acessar os arquivos armazenados no S3.\n",
    "\n",
    "<img src=\"./assets/vpc_endpoints.png\">\n",
    "\n",
    "Na categoria de serviço, foi escolhido \"Serviços da AWS\", e em seguida foi selecionado o Gateway do S3. O endpoint foi criado no VPC padrão, e a política de VPC endpoint foi definida como \"Acesso total\".\n",
    "\n",
    "<img src=\"./assets/vpc_create_endpoint.png\">\n",
    "\n",
    "<img src=\"./assets/vpc_endpoint_services.png\">\n",
    "\n",
    "<img src=\"./assets/vpc_endpoint_policy.png\">\n",
    "\n",
    "<img src=\"./assets/vpc_endpoint_created.png\">\n",
    "\n",
    "Por fim, a conexão criada (`mvp-redshift`) foi testada com sucesso, conforme apresentado na imagem abaixo:\n",
    "\n",
    "<img src=\"./assets/glue_test_connection.png\">\n",
    "\n",
    "<img src=\"./assets/glue_connection_successful.png\">\n",
    "\n",
    "\n",
    "### Executando o ETL job\n",
    "\n",
    "De volta ao nosso ETL job, podemos finalizar a configuração do alvo e finalmente executá-lo.\n",
    "\n",
    "Na aba \"Job details\", foi definida a função do IAM associada ao job (`Mvp-Glue`), ajustado o número de *workers* para 2 e o *timeout* do job para 4 minutos. Após salvar o ETL job, este foi executado com sucesso, extraindo os dados do S3, realizando as transformações desejadas e carregando-os para o Amazon Redshift.\n",
    "\n",
    "<img src=\"./assets/job_target_after.png\">\n",
    "\n",
    "<img src=\"./assets/job_details_1.png\">\n",
    "\n",
    "<img src=\"./assets/job_details_2.png\">\n",
    "\n",
    "<img src=\"./assets/job_saved.png\">\n",
    "\n",
    "<img src=\"./assets/job_run.png\">\n",
    "\n",
    "<img src=\"./assets/redshift_query_after_job.png\">\n",
    "\n",
    "\n",
    "### Transformações aplicadas\n",
    "\n",
    "Nessa seção são exibidas as transformações aplicadas a cada uma das tabelas da base de dados.\n",
    "\n",
    "#### Tabela Vendedor\n",
    "\n",
    "<img src=\"./assets/transform_vendedor.png\">\n",
    "\n",
    "#### Tabela Produto\n",
    "\n",
    "<img src=\"./assets/transform_produto.png\">\n",
    "\n",
    "#### Tabela Pedido\n",
    "\n",
    "<img src=\"./assets/transform_pedido.png\">\n",
    "\n",
    "#### Tabela Cliente\n",
    "\n",
    "<img src=\"./assets/transform_cliente.png\">\n",
    "\n",
    "#### Tabela Review\n",
    "\n",
    "<img src=\"./assets/transform_review.png\">\n",
    "\n",
    "#### Tabela Pagamento\n",
    "\n",
    "<img src=\"./assets/transform_pagamento.png\">\n",
    "\n",
    "#### Tabela Tempo\n",
    "\n",
    "<img src=\"./assets/transform_tempo_1.png\">\n",
    "\n",
    "Para o caso particular da tabela Tempo, foi utilizada uma transformação (do tipo SQL Query) para extrair informações de dia, mês, ano, hora e minuto da variável do tipo timestamp.\n",
    "\n",
    "<img src=\"./assets/transform_tempo_2.png\">\n",
    "\n",
    "#### Tabela Venda\n",
    "\n",
    "<img src=\"./assets/transform_venda_1.png\">\n",
    "\n",
    "Para o caso particular da tabela Venda, foi utilizada uma transformação (do tipo SQL Query) para agregar as linhas referentes a um mesmo pedido, de um mesmo item e mesmo vendedor.\n",
    "\n",
    "<img src=\"./assets/transform_venda_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catálogo de dados\n",
    "\n",
    "Nessa etapa, as tabelas armazenadas no Amazon Redshift serão adicionadas ao serviço de catálogo de dados da AWS, o **Glue Data Catalog**. Para isso, será criado um **Glue Crawler**, que acessará nosso Data Warehouse para efetuar as operações necessárias.\n",
    "\n",
    "<img src=\"./assets/crawler_create.png\">\n",
    "\n",
    "Nas propriedades do crawler, seu nome foi definido como `redshift_crawler`:\n",
    "\n",
    "<img src=\"./assets/crawler_properties.png\">\n",
    "\n",
    "Em seguida, foi necessário adicionar a fonte de dados, como exibido na figura abaixo. A fonte de dados foi definida como sendo do tipo **JDBC**, a conexão `mvp-redshift` criada anteriormente foi escolhida e o caminho aponta para todas as tabelas dentro de `dev/public`:\n",
    "\n",
    "<img src=\"./assets/crawler_add_data_source.png\">\n",
    "\n",
    "<img src=\"./assets/crawler_data_source.png\">\n",
    "\n",
    "Nas configurações de segurança, foi escolhida a função do IAM `Mvp-Glue`, também criada anteriormente:\n",
    "\n",
    "<img src=\"./assets/crawler_security.png\">\n",
    "\n",
    "Por fim, nas configurações de saída, foi necessário criar um database no Glue para receber os dados de catálogo. Essa base de dados foi criada com o nome de `mvp_ecommerce_sales_analysis`:\n",
    "\n",
    "<img src=\"./assets/crawler_create_database.png\">\n",
    "\n",
    "<img src=\"./assets/crawler_database_created.png\">\n",
    "\n",
    "<img src=\"./assets/crawler_output.png\">\n",
    "\n",
    "O crawler foi criado e executado com sucesso, criando oito novas tabelas na base de dados `mvp_ecommerce_sales_analysis`:\n",
    "\n",
    "<img src=\"./assets/crawler_created.png\">\n",
    "\n",
    "<img src=\"./assets/crawler_run.png\">\n",
    "\n",
    "<img src=\"./assets/crawler_database_with_tables.png\">\n",
    "\n",
    "Para cada atributo de cada tabela, foi adicionada uma breve descrição a respeito do mesmo, em conjunto com seus valores esperados:\n",
    "\n",
    "<img src=\"./assets/catalog_cliente.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_pagamento.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_pedido.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_produto.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_review.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_tempo.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_venda.png\">\n",
    "\n",
    "<img src=\"./assets/catalog_vendedor.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos dados\n",
    "\n",
    "Para a análise dos dados, foram criados notebooks dentro do Amazon Redshift, acessando diretamente a base de dados. Esses notebooks foram disponibilizados no repositório desse trabalho sob os nomes de `redshift_data-quality-analysis.ipynb` e `redshift_business-problem-analysis.ipynb`. Nesses arquivos é possível verificar as consultas realizadas e conclusões obtidas em cada etapa do processo. \n",
    "\n",
    "No entanto, a plataforma não permite a exportação do arquivo em formato PDF ou similar, e por isso não é possível verificar os resultados das consultas nos arquivos citados. Sendo assim, nessa seção serão disponibilizadas capturas de tela como forma de evidenciar o processo realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualidade de dados\n",
    "\n",
    "Como uma primeira etapa de análise, será avaliada a qualidade dos dados armazenados. Sendo assim, será verificada a existência de valores nulos, fora dos domínios definidos na etapa de modelagem ou em discordância com as regras de negócio observadas. Também serão verificados os valores mínimo, máximo e médio para as variáveis categóricas e possíveis categorias para as variáveis categóricas.\n",
    "\n",
    "É esperado que os dados não apresentem problemas de qualidade, visto que estes foram curados e bem tratados antes de serem disponibilizados na plataforma do Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Vendedor\n",
    "\n",
    "Essa tabela possui três colunas:\n",
    "\n",
    "- `seller_id`: identificador único para cada vendedor;\n",
    "- `seller_city`: cidade onde o vendedor está localizado;\n",
    "- `seller_state`: unidade federativa onde o vendedor está localizado.\n",
    "\n",
    "É esperado um número de valores distintos de id igual ao de registros na tabela, e no máximo 27 diferentes estados (contando o Distrito Federal). Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os possíveis valores da variável categórica são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/seller_states.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Produto\n",
    "\n",
    "Essa tabela possui seis colunas:\n",
    "\n",
    "- `product_id`: identificador único para cada registro de produto;\n",
    "- `product_category`: categoria do produto;\n",
    "- `product_weight`: peso do produto, em gramas;\n",
    "- `product_lenght`: comprimento do produto, em centímetros;\n",
    "- `product_height`: altura do produto, em centímetros;\n",
    "- `product_width`: largura do produto, em centímetros.\n",
    "\n",
    "É esperado que exista um id para cada registro na tabela. Também é esperado que as medidas de peso, comprimento, altura e largura sejam positivas. Foram encontrados dois produtos com valores nulos para as dimensões físicas. Uma hipótese é de que esses sejam produtos digitais, sem características físicas.\n",
    "\n",
    "Os valores máximo, mínimo e médio das variáveis quantitativas são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/product_max_min.png\">\n",
    "\n",
    "<img src=\"./assets/product_min_avg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Pedido\n",
    "\n",
    "Essa tabela possui três colunas:\n",
    "\n",
    "- `order_id`: identificador único do pedido;\n",
    "- `customer_id`: identificador do cliente que realizou o pedido;\n",
    "- `order_status`: status do pedido.\n",
    "\n",
    "É esperado que exista um único id para cada registro da tabela. Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os possíveis valores da variável categórica são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/order_statuses.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Cliente\n",
    "\n",
    "Essa tabela possui três colunas:\n",
    "\n",
    "- `customer_id`: identificador único para cada cliente;\n",
    "- `customer_city`: cidade onde o cliente está localizado;\n",
    "- `customer_state`: unidade federativa onde o cliente está localizado.\n",
    "\n",
    "É esperado um número de valores distintos de id igual ao de registros na tabela, e no máximo 27 diferentes estados (contando o Distrito Federal). Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os possíveis valores da variável categórica são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/customer_states.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Review\n",
    "\n",
    "Essa tabela possui três colunas:\n",
    "\n",
    "- `review_id`: identificador único do review;\n",
    "- `order_id`: id do pedido ao qual o review se refere;\n",
    "- `review_score`: nota dada para o pedido no review.\n",
    "\n",
    "É esperado um id para cada registro da tabela e um valor de score entre 1 e 5. Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os valores máximo, mínimo e médio da variável quantitativa são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/review_max_min_avg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Pagamento\n",
    "\n",
    "Essa tabela possui seis colunas:\n",
    "\n",
    "- `payment_id`: identificador único do pagamento;\n",
    "- `order_id`: id do pedido associado ao pagamento;\n",
    "- `payment_sequential`: número do pagamento dentro do pedido;\n",
    "- `payment_type`: forma de pagamento;\n",
    "- `payment_installments`: número de parcelas do pagamento;\n",
    "- `payment_value`: valor do pagamento.\n",
    "\n",
    "É esperado um id para cada registro da tabela, um número de parcelas igual ou maior que 1 e um valor de pagamento positivo. Nesse caso, foram observados alguns pagamentos com valor igual a zero, que provavelmente são explicados pela utilização de vouchers.\n",
    "\n",
    "Os possíveis valores da variável categórica são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/payment_types.png\">\n",
    "\n",
    "Os valores máximo, mínimo e médio das variáveis quantitativas são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/payment_max_min.png\">\n",
    "\n",
    "<img src=\"./assets/payment_price_zero.png\">\n",
    "\n",
    "<img src=\"./assets/payment_avg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Tempo\n",
    "\n",
    "Essa tabela possui sete atributos:\n",
    "\n",
    "- `time_id`: identificador único do registro de tempo;\n",
    "- `order_id`: id do pedido associado a esse tempo de compra;\n",
    "- `time_day`: dia do mês de realização do pedido;\n",
    "- `time_month`: mês de realização do pedido;\n",
    "- `time_year`: ano de realização do pedido;\n",
    "- `time_hour`: hora do dia na qual o pedido foi realizado;\n",
    "- `time_minute`: minuto em que o pedido foi realizado.\n",
    "\n",
    "É esperado um id único para cada registro da tabela, o dia limitado entre 1 e 31, o mês limitado entre 1 e 12, o ano entre 2016 e 2018, a hora entre 0 e 23 e o minuto entre 0 e 59. Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os valores máximo, mínimo e médio das variáveis quantitativas são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/time_max.png\">\n",
    "\n",
    "<img src=\"./assets/time_min.png\">\n",
    "\n",
    "<img src=\"./assets/time_avg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Venda\n",
    "\n",
    "Essa tabela possui seis colunas:\n",
    "\n",
    "- `order_id`: número do pedido associado à venda;\n",
    "- `product_id`: número do produto associado à venda;\n",
    "- `seller_id`: número do vendedor associado à venda;\n",
    "- `quantity`: quantidade de itens vendida;\n",
    "- `price`: preço total da venda;\n",
    "- `freight_value`: preço total de frete.\n",
    "\n",
    "É esperado que a quantidade, preço e valor de frete sejam positivos. Durante as consultas, não foram encontradas incosistências.\n",
    "\n",
    "Os valores máximo, mínimo e médio das variáveis quantitativas são exibidos abaixo:\n",
    "\n",
    "<img src=\"./assets/sale_max_min.png\">\n",
    "\n",
    "<img src=\"./assets/sale_min_avg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solução do problema\n",
    "\n",
    "Nessa etapa, o problema será finalmente analisado e resolvido, de forma a responder as perguntas levantadas no objetivo desse trabalho. Foram essas:\n",
    "\n",
    "- Quais são os produtos mais vendidos no e-commerce?\n",
    "- Qual o preço médio das vendas?\n",
    "- Qual estado ou região do Brasil realiza mais compras online?\n",
    "- Qual a forma de pagamento de preferência?\n",
    "- Cada pedido possui em média quantos itens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Quais são os produtos mais vendidos no e-commerce?\n",
    "\n",
    "<img src=\"./assets/question_1_1.png\">\n",
    "\n",
    "<img src=\"./assets/question_1_2.png\">\n",
    "\n",
    "<img src=\"./assets/question_1_3.png\">\n",
    "\n",
    "<img src=\"./assets/question_1_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Qual o preço médio das vendas?\n",
    "\n",
    "<img src=\"./assets/question_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Qual estado ou região do Brasil realiza mais compras online?\n",
    "\n",
    "<img src=\"./assets/question_3_1.png\">\n",
    "\n",
    "<img src=\"./assets/question_3_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Qual a forma de pagamento de preferência?\n",
    "\n",
    "<img src=\"./assets/question_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Cada pedido possui em média quantos itens?\n",
    "\n",
    "<img src=\"./assets/question_5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explorando as regras de associação\n",
    "\n",
    "<img src=\"./assets/rules_1.png\">\n",
    "\n",
    "<img src=\"./assets/rules_2.png\">\n",
    "\n",
    "<img src=\"./assets/rules_3.png\">\n",
    "\n",
    "<img src=\"./assets/rules_4.png\">\n",
    "\n",
    "<img src=\"./assets/rules_5.png\">\n",
    "\n",
    "<img src=\"./assets/rules_6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões Finais\n",
    "\n",
    "Nesse trabalho, os serviços de nuvem foram utilizados para construção de um ambiente analítico escalável, capaz de lidar com um grande volume de dados. O S3 foi utilizado para armazenamento dos dados, o AWS Glue foi aplicado no processo de ETL e o Amazon Redshift Serverless foi escolhido como serviço de Data Warehouse.\n",
    "\n",
    "A partir da linguagem SQL, foi possível extrair as informações desejadas da base de dados de forma rápida e eficiente, evidenciando a praticidade e poder das plataformas de nuvem. Além das respostas a perguntas mais diretas sobre os problemas de negócio, ainda foram obtidas métricas ligadas a regras de associação, destacando quais produtos possuem maior coocorrência, ou seja, que costumam ser comprados em conjunto. Os dados ainda permitiriam outras análises aqui não exploradas, como aquelas relacionadas a dimensão tempo, a localização dos vendedores e as pontuações dadas aos pedidos, que ficam como propostas de trabalhos futuros.\n",
    "\n",
    "Em um ambiente de negócios cada vez mais competitivo, as empresas que utilizam o BI de maneira eficaz têm uma vantagem significativa. Elas podem identificar oportunidades mais rapidamente, reagir às mudanças do mercado com agilidade e tomar decisões mais informadas do que a concorrência. Dessa forma, as análises realizadas podem ser utilizadas por uma organização para a obtenção de insights e para a tomada de decisões mais assertivas, orientadas por dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
